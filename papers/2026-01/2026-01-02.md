# arXiv Papers - 2026-01-02

## Papers of Interest

### 1. SpaceTimePilot: Generative Rendering of Dynamic Scenes Across Space and Time

**Authors:** Zhening Huang, Hyeonho Jeong, Xuelin Chen et al.  
**Published:** 2025-12-31  
**arXiv ID:** 2512.25075v1  
**Link:** https://arxiv.org/abs/2512.25075v1

**Abstract (excerpt):**  
We present SpaceTimePilot, a video diffusion model that disentangles space and time for controllable generative rendering. Given a monocular video, SpaceTimePilot can independently alter the camera viewpoint and the motion sequence within the generative process, re-rendering the scene for continuous...

**My Notes:**
- Key contribution:
- Relevance to my work:
- Implementation ideas:

**Status:** ðŸ“š To Read

---

### 2. Coordinated Humanoid Manipulation with Choice Policies

**Authors:** Haozhi Qi, Yen-Jen Wang, Toru Lin et al.  
**Published:** 2025-12-31  
**arXiv ID:** 2512.25072v1  
**Link:** https://arxiv.org/abs/2512.25072v1

**Abstract (excerpt):**  
Humanoid robots hold great promise for operating in human-centric environments, yet achieving robust whole-body coordination across the head, hands, and legs remains a major challenge. We present a system that combines a modular teleoperation interface with a scalable learning framework to address t...

**My Notes:**
- Key contribution:
- Relevance to my work:
- Implementation ideas:

**Status:** ðŸ“š To Read

---

### 3. Scaling Open-Ended Reasoning to Predict the Future

**Authors:** Nikhil Chandak, Shashwat Goel, Ameya Prabhu et al.  
**Published:** 2025-12-31  
**arXiv ID:** 2512.25070v1  
**Link:** https://arxiv.org/abs/2512.25070v1

**Abstract (excerpt):**  
High-stakes decision making involves reasoning under uncertainty about the future. In this work, we train language models to make predictions on open-ended forecasting questions. To scale up training data, we synthesize novel forecasting questions from global events reported in daily news, using a f...

**My Notes:**
- Key contribution:
- Relevance to my work:
- Implementation ideas:

**Status:** ðŸ“š To Read

---

### 4. From Inpainting to Editing: A Self-Bootstrapping Framework for Context-Rich Visual Dubbing

**Authors:** Xu He, Haoxian Zhang, Hejia Chen et al.  
**Published:** 2025-12-31  
**arXiv ID:** 2512.25066v1  
**Link:** https://arxiv.org/abs/2512.25066v1

**Abstract (excerpt):**  
Audio-driven visual dubbing aims to synchronize a video's lip movements with new speech, but is fundamentally challenged by the lack of ideal training data: paired videos where only a subject's lip movements differ while all other visual conditions are identical. Existing methods circumvent this wit...

**My Notes:**
- Key contribution:
- Relevance to my work:
- Implementation ideas:

**Status:** ðŸ“š To Read

---

### 5. Many Minds from One Model: Bayesian Transformers for Population Intelligence

**Authors:** Diji Yang, Yi Zhang  
**Published:** 2025-12-31  
**arXiv ID:** 2512.25063v1  
**Link:** https://arxiv.org/abs/2512.25063v1

**Abstract (excerpt):**  
Despite their scale and success, modern transformers are almost universally trained as single-minded systems: optimization produces one deterministic set of parameters, representing a single functional hypothesis about the data. Motivated by the idea that intelligence emerge from many minds, we prop...

**My Notes:**
- Key contribution:
- Relevance to my work:
- Implementation ideas:

**Status:** ðŸ“š To Read

---


## Reading Progress
- Total papers tracked: 5
- Papers read this month: 0
- Implementation attempts: 0

## Tags
#machine-learning #deep-learning #research
