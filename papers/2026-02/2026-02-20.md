# arXiv Papers - 2026-02-20

## Papers of Interest

### 1. OpenEarthAgent: A Unified Framework for Tool-Augmented Geospatial Agents

**Authors:** Akashah Shabbir, Muhammad Umer Sheikh, Muhammad Akhtar Munir et al.  
**Published:** 2026-02-19  
**arXiv ID:** 2602.17665v1  
**Link:** https://arxiv.org/abs/2602.17665v1

**Abstract (excerpt):**  
Recent progress in multimodal reasoning has enabled agents that can interpret imagery, connect it with language, and perform structured analytical tasks. Extending such capabilities to the remote sensing domain remains challenging, as models must reason over spatial scale, geographic structures, and...

**My Notes:**
- Key contribution:
- Relevance to my work:
- Implementation ideas:

**Status:** ðŸ“š To Read

---

### 2. Sink-Aware Pruning for Diffusion Language Models

**Authors:** Aidar Myrzakhan, Tianyi Li, Bowei Guo et al.  
**Published:** 2026-02-19  
**arXiv ID:** 2602.17664v1  
**Link:** https://arxiv.org/abs/2602.17664v1

**Abstract (excerpt):**  
Diffusion Language Models (DLMs) incur high inference cost due to iterative denoising, motivating efficient pruning. Existing pruning heuristics largely inherited from autoregressive (AR) LLMs, typically preserve attention sink tokens because AR sinks serve as stable global anchors. We show that thi...

**My Notes:**
- Key contribution:
- Relevance to my work:
- Implementation ideas:

**Status:** ðŸ“š To Read

---

### 3. When Vision Overrides Language: Evaluating and Mitigating Counterfactual Failures in VLAs

**Authors:** Yu Fang, Yuchun Feng, Dong Jing et al.  
**Published:** 2026-02-19  
**arXiv ID:** 2602.17659v1  
**Link:** https://arxiv.org/abs/2602.17659v1

**Abstract (excerpt):**  
Vision-Language-Action models (VLAs) promise to ground language instructions in robot control, yet in practice often fail to faithfully follow language. When presented with instructions that lack strong scene-specific supervision, VLAs suffer from counterfactual failures: they act based on vision sh...

**My Notes:**
- Key contribution:
- Relevance to my work:
- Implementation ideas:

**Status:** ðŸ“š To Read

---

### 4. MARS: Margin-Aware Reward-Modeling with Self-Refinement

**Authors:** Payel Bhattacharjee, Osvaldo Simeone, Ravi Tandon  
**Published:** 2026-02-19  
**arXiv ID:** 2602.17658v1  
**Link:** https://arxiv.org/abs/2602.17658v1

**Abstract (excerpt):**  
Reward modeling is a core component of modern alignment pipelines including RLHF and RLAIF, underpinning policy optimization methods including PPO and TRPO. However, training reliable reward models relies heavily on human-labeled preference data, which is costly and limited, motivating the use of da...

**My Notes:**
- Key contribution:
- Relevance to my work:
- Implementation ideas:

**Status:** ðŸ“š To Read

---

### 5. What Language is This? Ask Your Tokenizer

**Authors:** Clara Meister, Ahmetcan Yavuz, Pietro Lesci et al.  
**Published:** 2026-02-19  
**arXiv ID:** 2602.17655v1  
**Link:** https://arxiv.org/abs/2602.17655v1

**Abstract (excerpt):**  
Language Identification (LID) is an important component of many multilingual natural language processing pipelines, where it facilitates corpus curation, training data analysis, and cross-lingual evaluation of large language models. Despite near-perfect performance on high-resource languages, existi...

**My Notes:**
- Key contribution:
- Relevance to my work:
- Implementation ideas:

**Status:** ðŸ“š To Read

---


## Reading Progress
- Total papers tracked: 5
- Papers read this month: 0
- Implementation attempts: 0

## Tags
#machine-learning #deep-learning #research
